{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from options import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from vectorizer import init_tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarigian/miniconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_tweets = pd.read_table(DATA_PATH+POS_TWEETS_FILE, names=['tweet','sentiment'])\n",
    "pos_tweets['sentiment'] = 'pos'\n",
    "neg_tweets = pd.read_table(DATA_PATH+NEG_TWEETS_FILE ,names=['tweet','sentiment'])\n",
    "neg_tweets['sentiment'] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pos_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# neg_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive tweets shape:  (971, 2)\n",
      "negative tweets shape:  (947, 2)\n"
     ]
    }
   ],
   "source": [
    "print('positive tweets shape: ',pos_tweets.shape)\n",
    "print('negative tweets shape: ',neg_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1918, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([pos_tweets, neg_tweets], axis=0)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  sea doo pro sea scooter ( sports with the port...        NaN\n",
       "1  <user> shucks well i work all week so now i ca...        NaN\n",
       "2            i cant stay away from bug thats my baby        NaN\n",
       "3  <user> no ma'am ! ! ! lol im perfectly fine an...        NaN\n",
       "4  whenever i fall asleep watching the tv , i alw...        NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets = pd.read_table(DATA_PATH+TEST_TWEETS_FILE, names=['tweet','sentiment'])\n",
    "test_tweets['tweet'] = test_tweets.apply(lambda tweet: remove_tweet_id(tweet['tweet']), axis=1)\n",
    "test_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tweets['tagged'] = tweets.apply(lambda tweet: pos_tag(tweet['tweet']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Settings:\n",
      "\n",
      "furl :\t True\n",
      "fpunctuation :\t True\n",
      "fsmall_words :\t True\n",
      "fdigits :\t True\n",
      "fduplicates :\t True\n",
      "frepeated_chars :\t True\n",
      "save :\t False\n",
      "fuser :\t True\n",
      "fhashtag :\t True\n",
      "-\n",
      "\n",
      "Tweets Preprocessing for the Training set started\n",
      "\n",
      "\n",
      "There is no cached file for preprocessed tweets\n",
      "\n",
      "Number of tweets before duplicates removal:\t 1918\n",
      "Number of tweets after duplicates removal:\t 1791\n",
      "Duplicates removal DONE\n",
      "Repeated characters filtering DONE\n",
      "Punctuation filtering DONE\n",
      "User filtering DONE\n",
      "Url filtering DONE\n",
      "Hashtag filtering DONE\n",
      "Digits DONE\n",
      "Small words filtering DONE\n",
      "\n",
      " Preprocessed tweets did not saved...\n",
      "\n",
      "Tweets Preprocessing have been successfully finished!\n"
     ]
    }
   ],
   "source": [
    "tweets = preprocessing(tweets,train=True, params=preprocessing_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets final representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dunno justin read mention not only justin and ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic dumb won even crop out your...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just put casper box looved the battle crakkbitch</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thanks sir don trip lil mama just keep doin thang</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting brother tmr the bestest birthday gift...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yay lifecompleted tweet facebook let know please</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dnextalbumtitle feel for you rollercoaster lif...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>workin hard hardly workin hardee with future c...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>saw replying bit</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>this were belong</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>andd cheer nationals</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>send invitation shop line here you will find e...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>just woke finna church</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>agreed more days left tho</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>monet with katemelo</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>like damm lexis got lot say when twitter lol</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>grateful today for dream fulfilled heart full ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>home affairs shall later</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>barca bout beat real madrid saturday doe</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lot parts asia especially rats that live the c...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wasn even sleeping shut cho ole back sleep loo...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>have the worlds best dad</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jaeyay werna meeting khatam hojaeygi baaqi but...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>one doubts that ability</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>check tweet pic out that was the outfit before...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>just got mid term and impressed happy</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>summer days work from ish home shower eat out ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lol noo food friend</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>millionbritneyfan and tweet</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>but seriously though called vanity fairest</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>and evil people lord will fight for</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>lincoln navigator chrome door handles covers k...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>mario badescu buffering lotion health and beau...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>practitioner guide software test design hardco...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>custom picture frame poster frame wide complet...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>maxpedition inch clip phone holster khaki grea...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>and was right they let slide</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>just love how never texts back</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>can find one direction top can wear for dance ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>you not coming grand march</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>asics gel kinsei women white capri blue lightn...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>though</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>garden life perfect food raw organic powder he...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>shine like does the anthology audio shine like...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>wondering has left yet</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>awesome can believe that series done</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>wooden mallet fold away wall desk oak whether ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>water and scratch resistant case for garmin to...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>its pouring down robyn grim haha sitting sandw...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>apple ipod touch generation white</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>niall please just one tweet for just one retwe...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>happy birthday thornsten husgss wishh you know...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>its like antarctica this bitch need the heat f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>stylecraft spaced board and batten mahogany ex...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>please follow back you follow sister and reall...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>tis not bad people make seem don let twitter g...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>said that she tries respond least barbz day ou...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>shut not please don eat cause you eat all gone...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>sorry can come amazing show jakarta the fans w...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>nice congrats today failed math test and physi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1791 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet sentiment\n",
       "0    dunno justin read mention not only justin and ...       pos\n",
       "1    because your logic dumb won even crop out your...       pos\n",
       "2     just put casper box looved the battle crakkbitch       pos\n",
       "3    thanks sir don trip lil mama just keep doin thang       pos\n",
       "4    visiting brother tmr the bestest birthday gift...       pos\n",
       "5     yay lifecompleted tweet facebook let know please       pos\n",
       "6    dnextalbumtitle feel for you rollercoaster lif...       pos\n",
       "7    workin hard hardly workin hardee with future c...       pos\n",
       "8                                     saw replying bit       pos\n",
       "9                                     this were belong       pos\n",
       "10                                andd cheer nationals       pos\n",
       "11   send invitation shop line here you will find e...       pos\n",
       "12                              just woke finna church       pos\n",
       "13                           agreed more days left tho       pos\n",
       "14                                 monet with katemelo       pos\n",
       "15        like damm lexis got lot say when twitter lol       pos\n",
       "16   grateful today for dream fulfilled heart full ...       pos\n",
       "17                            home affairs shall later       pos\n",
       "18            barca bout beat real madrid saturday doe       pos\n",
       "19   lot parts asia especially rats that live the c...       pos\n",
       "20   wasn even sleeping shut cho ole back sleep loo...       pos\n",
       "21                            have the worlds best dad       pos\n",
       "22   jaeyay werna meeting khatam hojaeygi baaqi but...       pos\n",
       "23                             one doubts that ability       pos\n",
       "24   check tweet pic out that was the outfit before...       pos\n",
       "25               just got mid term and impressed happy       pos\n",
       "26   summer days work from ish home shower eat out ...       pos\n",
       "27                                 lol noo food friend       pos\n",
       "28                         millionbritneyfan and tweet       pos\n",
       "29          but seriously though called vanity fairest       pos\n",
       "..                                                 ...       ...\n",
       "910                and evil people lord will fight for       neg\n",
       "911  lincoln navigator chrome door handles covers k...       neg\n",
       "912  mario badescu buffering lotion health and beau...       neg\n",
       "913  practitioner guide software test design hardco...       neg\n",
       "914  custom picture frame poster frame wide complet...       neg\n",
       "915  maxpedition inch clip phone holster khaki grea...       neg\n",
       "916                       and was right they let slide       neg\n",
       "917                     just love how never texts back       neg\n",
       "918  can find one direction top can wear for dance ...       neg\n",
       "919                         you not coming grand march       neg\n",
       "920  asics gel kinsei women white capri blue lightn...       neg\n",
       "921                                             though       neg\n",
       "922  garden life perfect food raw organic powder he...       neg\n",
       "923  shine like does the anthology audio shine like...       neg\n",
       "924                             wondering has left yet       neg\n",
       "925               awesome can believe that series done       neg\n",
       "926  wooden mallet fold away wall desk oak whether ...       neg\n",
       "928  water and scratch resistant case for garmin to...       neg\n",
       "929  its pouring down robyn grim haha sitting sandw...       neg\n",
       "930                  apple ipod touch generation white       neg\n",
       "937  niall please just one tweet for just one retwe...       neg\n",
       "938  happy birthday thornsten husgss wishh you know...       neg\n",
       "939  its like antarctica this bitch need the heat f...       neg\n",
       "940  stylecraft spaced board and batten mahogany ex...       neg\n",
       "941  please follow back you follow sister and reall...       neg\n",
       "942  tis not bad people make seem don let twitter g...       neg\n",
       "943  said that she tries respond least barbz day ou...       neg\n",
       "944  shut not please don eat cause you eat all gone...       neg\n",
       "945  sorry can come amazing show jakarta the fans w...       neg\n",
       "946  nice congrats today failed math test and physi...       neg\n",
       "\n",
       "[1791 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.isnull(tweets).any(1).nonzero()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequencies TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize bag of words (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf Vectorizer settings\n",
      "\n",
      "min_df :\t 5\n",
      "max_features :\t 5000\n",
      "sublinear_tf :\t True\n",
      "use_idf :\t True\n",
      "max_df :\t 0.8\n",
      "ngram_range :\t (1, 1)\n",
      "tokenizer :\t True\n",
      "number_of_stopwords :\t 153\n",
      "-\n",
      "\n",
      "stopwords:\n",
      " frozenset({'elsewhere', 'everywhere', 'however', 'needn', 'in', 'whereupon', 'it', 'indeed', 'around', 'not', 'eight', 'empty', 'its', 'herein', 'couldn', 'yet', 'few', 'for', 'than', 'behind', 'wasn', 'anywhere', 'under', 'by', 'nobody', 'since', 'won', 'has', 'something', 'wherever', 'would', 'shouldn', 'co', 'whatever', 'myself', 'are', 'them', 'himself', 'first', 'through', 'this', 'many', 'was', 'down', 'wherein', 'him', 'forty', 's', 'until', 'me', 'an', 'mill', 'thence', 'often', 'etc', 'inc', 'had', 'another', 'us', 'two', 'my', 'i', 'herself', 'rather', 'hundred', 'most', 'must', 'others', 'next', 'be', 'please', 'about', 'amount', 'less', 'against', 'namely', 'such', 'take', 'been', 'll', 'doing', 'afterwards', 'back', 'but', 'top', 'ain', 'although', 'made', 'put', 'anyway', 'so', 'weren', 'everyone', 'among', 'besides', 'hereupon', 'into', 'already', 'is', 'go', 'should', 'what', 'yourself', 'don', 'yourselves', 'across', 'enough', 'their', 'get', 'moreover', 'do', 'may', 'cant', 'now', 'neither', 'o', 'or', 'itself', 'fill', 'meanwhile', 'am', 'a', 'because', 'here', 'if', 'interest', 'seeming', 'much', 'her', 'which', 'more', 'ltd', 'whole', 'whoever', 'these', 'show', 'just', 'well', 'theirs', 'former', 'otherwise', 'whenever', 'above', 'once', 'our', 'bottom', 'there', 'con', 'formerly', 'therefore', 'some', 'did', 'fifteen', 'while', 'over', 'does', 'move', 'onto', 'too', 'perhaps', 'together', 'thick', 'becoming', 'even', 'three', 'were', 'the', 'up', 'hadn', 'd', 'never', 'he', 'except', 'five', 'they', 'cannot', 'thereafter', 'found', 'themselves', 'ever', 'via', 'ours', 'hers', 'beforehand', 'having', 'anyone', 'beyond', 'latterly', 'beside', 'find', 'upon', 'somehow', 'out', 'ma', 'on', 'detail', 'seem', 'sincere', 'side', 'describe', 'didn', 'm', 'several', 'latter', 'couldnt', 'from', 'mightn', 'everything', 're', 'six', 'aren', 'system', 'though', 'eleven', 'no', 'per', 'always', 'own', 'same', 'and', 'below', 'being', 'one', 'thin', 'whose', 'de', 'have', 'fire', 'haven', 'thereby', 'whereby', 'twenty', 'nine', 'none', 'nowhere', 'nothing', 'whence', 'cry', 'fifty', 'hasn', 'also', 'hereafter', 'will', 'thru', 'amongst', 'other', 'within', 'anyhow', 'mine', 'she', 'someone', 'you', 'shan', 'of', 'can', 'after', 'again', 'anything', 'either', 'then', 'ourselves', 'become', 'any', 'where', 'before', 'how', 'along', 'between', 'call', 'thereupon', 'all', 'done', 'whereas', 'least', 'wouldn', 'only', 'your', 'thus', 'without', 'third', 'seemed', 'why', 'twelve', 'whom', 'eg', 'keep', 'isn', 'due', 'sixty', 'during', 't', 'his', 'mostly', 'serious', 'both', 'could', 'hereby', 'off', 'bill', 'to', 'un', 'towards', 'with', 'sometime', 'seems', 've', 'whereafter', 'doesn', 'when', 'mustn', 'y', 'whither', 'each', 'yours', 'noone', 'who', 'becomes', 'front', 'somewhere', 'see', 'hence', 'sometimes', 'nevertheless', 'part', 'that', 'might', 'at', 'those', 'toward', 'became', 'every', 'as', 'last', 'give', 'name', 'nor', 'amoungst', 'further', 'whether', 'full', 'four', 'ten', 'almost', 'else', 'hasnt', 'we', 'ie', 'throughout', 'very', 'still', 'therein', 'alone'})\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = init_tfidf_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### polynomial expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (simple training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets['tweet'], tweets['sentiment'], test_size=split_params['test_size'], random_state=split_params['random_state'])\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test_vectors = tfidf_vectorizer.transform(X_test)\n",
    "#shape: (number_of_tweets, all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.68      0.40      0.50        81\n",
      "        pos       0.63      0.85      0.72        99\n",
      "\n",
      "avg / total       0.65      0.64      0.62       180\n",
      "\n",
      "score:  0.644444444444\n"
     ]
    }
   ],
   "source": [
    "nbclf = MultinomialNB()\n",
    "nbclf.fit(tfidf_train_vectors, y_train)\n",
    "prediction_bayes = nbclf.predict(tfidf_test_vectors)\n",
    "print(prediction_bayes.shape)\n",
    "print(classification_report(y_test, prediction_bayes))\n",
    "print('score: ',accuracy_score(y_test,prediction_bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice algorithm because it runs in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.60      0.59      0.60        81\n",
      "        pos       0.67      0.68      0.67        99\n",
      "\n",
      "avg / total       0.64      0.64      0.64       180\n",
      "\n",
      "score:  0.638888888889\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100,max_depth=100,n_jobs=-1,random_state=4)\n",
    "forest.fit(tfidf_train_vectors, y_train)\n",
    "y_pred_forest = forest.predict(tfidf_test_vectors)\n",
    "\n",
    "print(classification_report(y_test, y_pred_forest))\n",
    "print('score: ',accuracy_score(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classifier_linear = svm.SVC(kernel='linear')\n",
    "# classifier_linear.fit(tfidf_train_vectors, y_train)\n",
    "# prediction_linear = classifier_linear.predict(tfidf_test_vectors)\n",
    "\n",
    "# print(classification_report(y_test, prediction_linear))\n",
    "# print('score: ',accuracy_score(y_test,prediction_bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top k most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'good', 'follow', 'thanks', 'like', 'lol', 'day', 'know', 'time', 'got']\n"
     ]
    }
   ],
   "source": [
    "print(topk_most_important_features(tfidf_vectorizer, nbclf, k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-7.3987\tbattery        \t\t-4.0926\tlove           \n",
      "\t-7.3987\tbrand          \t\t-4.1579\tgood           \n",
      "\t-7.3987\tcamera         \t\t-4.1766\tfollow         \n",
      "\t-7.3987\tcollege        \t\t-4.2666\tthanks         \n",
      "\t-7.3987\tcomplete       \t\t-4.2742\tlike           \n",
      "\t-7.3987\tcustom         \t\t-4.3019\tlol            \n",
      "\t-7.3987\tdamn           \t\t-4.3498\tday            \n",
      "\t-7.3987\tdigital        \t\t-4.4074\tknow           \n",
      "\t-7.3987\tdvd            \t\t-4.4748\ttime           \n",
      "\t-7.3987\tedition        \t\t-4.5181\tgot            \n",
      "\t-7.3987\telectronics    \t\t-4.5869\thaha           \n",
      "\t-7.3987\tframe          \t\t-4.6852\twa             \n",
      "\t-7.3987\tglass          \t\t-4.7247\tthank          \n",
      "\t-7.3987\thardcover      \t\t-4.7327\twant           \n",
      "\t-7.3987\thealth         \t\t-4.8598\tgirl           \n",
      "\t-7.3987\tinch           \t\t-4.8744\tmake           \n",
      "\t-7.3987\tkit            \t\t-4.8864\tnight          \n",
      "\t-7.3987\tmemory         \t\t-4.9688\twait           \n",
      "\t-7.3987\tpack           \t\t-4.9858\ttoday          \n",
      "\t-7.3987\tpaperback      \t\t-5.0206\tgoing          \n",
      "\t-7.3987\tposter         \t\t-5.0583\thappy          \n",
      "\t-7.3987\train           \t\t-5.0752\tcome           \n",
      "\t-7.3987\tram            \t\t-5.0873\thope           \n",
      "\t-7.3987\treplacement    \t\t-5.0932\tlook           \n",
      "\t-7.3987\tsad            \t\t-5.1182\tright          \n",
      "\t-7.3987\tscience        \t\t-5.1452\tthink          \n",
      "\t-7.3987\tseason         \t\t-5.1577\they            \n",
      "\t-7.3987\tsilver         \t\t-5.1654\ttweet          \n",
      "\t-7.3987\ttest           \t\t-5.1706\tyeah           \n",
      "\t-7.3987\ttoy            \t\t-5.1802\tbirthday       \n",
      "\t-7.3987\twide           \t\t-5.1881\tneed           \n",
      "\t-7.3987\tworst          \t\t-5.2174\tbetter         \n",
      "\t-7.1295\tbrown          \t\t-5.2806\tgetting        \n",
      "\t-7.1054\tfinal          \t\t-5.2953\tna             \n",
      "\t-7.0646\twent           \t\t-5.2997\tgreat          \n",
      "\t-7.0555\tcont           \t\t-5.3017\thome           \n",
      "\t-7.0401\tago            \t\t-5.3057\tnew            \n",
      "\t-7.0345\tweather        \t\t-5.3165\tsay            \n",
      "\t-7.0218\tdesign         \t\t-5.3601\treally         \n",
      "\t-7.0191\ttech           \t\t-5.3669\tsong           \n",
      "\t-7.0180\thurt           \t\t-5.3685\tsleep          \n",
      "\t-7.0167\tidk            \t\t-5.3797\ttwitter        \n",
      "\t-7.0136\tbarca          \t\t-5.3802\tguy            \n",
      "\t-7.0106\tpost           \t\t-5.3841\tyes            \n",
      "\t-7.0038\tpaper          \t\t-5.4055\tlife           \n",
      "\t-7.0029\tholiday        \t\t-5.4069\tmorning        \n",
      "\t-6.9965\tawake          \t\t-5.4630\tpeople         \n",
      "\t-6.9740\tplayer         \t\t-5.4815\tsure           \n",
      "\t-6.9730\tbusy           \t\t-5.4844\tha             \n",
      "\t-6.9675\taway           \t\t-5.4901\tway            \n",
      "\t-6.9587\tmoney          \t\t-5.4910\tmind           \n",
      "\t-6.9529\tenglish        \t\t-5.5006\tmaybe          \n",
      "\t-6.9510\tpower          \t\t-5.5007\tsoon           \n",
      "\t-6.9299\tmum            \t\t-5.5030\tlong           \n",
      "\t-6.9256\tcase           \t\t-5.5104\tsmile          \n",
      "\t-6.9251\tsick           \t\t-5.5154\tfollowing      \n",
      "\t-6.9219\tjob            \t\t-5.5176\tyear           \n",
      "\t-6.9210\tstory          \t\t-5.5294\tstart          \n",
      "\t-6.9194\tfast           \t\t-5.5362\tlot            \n",
      "\t-6.8985\tblack          \t\t-5.5459\tgod            \n",
      "\t-6.8966\tend            \t\t-5.5502\ttho            \n",
      "\t-6.8958\tset            \t\t-5.5537\tgon            \n",
      "\t-6.8715\twood           \t\t-5.5600\tlive           \n",
      "\t-6.8538\tseries         \t\t-5.5617\ttonight        \n",
      "\t-6.8430\tmissed         \t\t-5.5636\tokay           \n",
      "\t-6.8222\tsomebody       \t\t-5.5718\tnice           \n",
      "\t-6.8026\tcold           \t\t-5.6082\tthing          \n",
      "\t-6.7970\tstudy          \t\t-5.6288\ttell           \n",
      "\t-6.7932\tgreen          \t\t-5.6687\treal           \n",
      "\t-6.7883\tperson         \t\t-5.6793\tamazing        \n",
      "\t-6.7769\tshort          \t\t-5.6804\tclass          \n",
      "\t-6.7515\tshare          \t\t-5.6846\tfree           \n",
      "\t-6.7482\twoman          \t\t-5.6859\ttomorrow       \n",
      "\t-6.7275\tbook           \t\t-5.6872\tactually       \n",
      "\t-6.7193\tcare           \t\t-5.6914\tlittle         \n",
      "\t-6.7185\tdad            \t\t-5.6956\tmean           \n",
      "\t-6.7173\tnoo            \t\t-5.7059\thehe           \n",
      "\t-6.7073\twanted         \t\t-5.7120\ttry            \n",
      "\t-6.7065\tstand          \t\t-5.7173\ttext           \n",
      "\t-6.7062\tanswer         \t\t-5.7177\tgame           \n",
      "\t-6.7056\tmissing        \t\t-5.7249\tcause          \n",
      "\t-6.6992\tseen           \t\t-5.7254\tshit           \n",
      "\t-6.6960\tline           \t\t-5.7500\ttrying         \n",
      "\t-6.6875\tsaturday       \t\t-5.7538\tremember       \n",
      "\t-6.6695\tred            \t\t-5.7614\ttalking        \n",
      "\t-6.6595\tstar           \t\t-5.7671\tpicture        \n",
      "\t-6.6575\tlight          \t\t-5.7683\thour           \n",
      "\t-6.6468\thappened       \t\t-5.7801\tcute           \n",
      "\t-6.6141\tsaw            \t\t-5.7817\tfriend         \n",
      "\t-6.6137\tlost           \t\t-5.7864\twish           \n",
      "\t-6.6116\ttired          \t\t-5.7888\tfun            \n",
      "\t-6.5987\tcover          \t\t-5.7957\tbaby           \n",
      "\t-6.5908\tleaving        \t\t-5.7968\tbed            \n",
      "\t-6.5849\tlil            \t\t-5.8025\tdont           \n",
      "\t-6.5681\treply          \t\t-5.8120\told            \n",
      "\t-6.5574\tfall           \t\t-5.8127\tweekend        \n",
      "\t-6.5531\tnotice         \t\t-5.8167\tlooking        \n",
      "\t-6.5452\tdidnt          \t\t-5.8252\tstay           \n",
      "\t-6.5432\tdog            \t\t-5.8275\tthought        \n",
      "\t-6.5400\tspecial        \t\t-5.8326\tlmao           \n",
      "\t-6.5384\twear           \t\t-5.8379\tearly          \n",
      "\t-6.5183\tanymore        \t\t-5.8472\twatch          \n",
      "\t-6.5177\tused           \t\t-5.8484\thair           \n",
      "\t-6.5127\ttrack          \t\t-5.8488\tfeel           \n",
      "\t-6.5056\twhite          \t\t-5.8492\tseriously      \n",
      "\t-6.4961\treview         \t\t-5.8529\tkiss           \n",
      "\t-6.4953\tgold           \t\t-5.8540\treason         \n",
      "\t-6.4921\tbox            \t\t-5.8547\tsend           \n",
      "\t-6.4919\tsingle         \t\t-5.8589\tsweet          \n",
      "\t-6.4918\tfeeling        \t\t-5.8616\taww            \n",
      "\t-6.4712\tticket         \t\t-5.8662\tlet            \n",
      "\t-6.4698\tfacebook       \t\t-5.8712\twork           \n",
      "\t-6.4529\taha            \t\t-5.8743\tlady           \n",
      "\t-6.4407\teating         \t\t-5.8748\till            \n",
      "\t-6.4401\tbad            \t\t-5.8766\tbest           \n",
      "\t-6.4329\tbreak          \t\t-5.8783\tforever        \n",
      "\t-6.4299\twrong          \t\t-5.8793\tglad           \n",
      "\t-6.4261\tfood           \t\t-5.9051\tlater          \n",
      "\t-6.4206\tblue           \t\t-5.9109\ttrue           \n",
      "\t-6.4170\tohh            \t\t-5.9128\tschool         \n",
      "\t-6.4143\tsmall          \t\t-5.9240\tdirection      \n",
      "\t-6.4133\tcrazy          \t\t-5.9244\tlaugh          \n",
      "\t-6.4094\tespecially     \t\t-5.9259\thead           \n",
      "\t-6.4049\tsaying         \t\t-5.9272\tproud          \n",
      "\t-6.4015\tdick           \t\t-5.9304\tsaid           \n",
      "\t-6.4002\tonline         \t\t-5.9383\tphone          \n",
      "\t-6.3903\ttold           \t\t-5.9406\tbring          \n",
      "\t-6.3812\teat            \t\t-5.9450\tdoin           \n",
      "\t-6.3758\tprom           \t\t-5.9464\tdate           \n",
      "\t-6.3691\tharry          \t\t-5.9481\tima            \n",
      "\t-6.3680\tamerican       \t\t-5.9539\tbrother        \n",
      "\t-6.3674\thalf           \t\t-5.9580\tboy            \n",
      "\t-6.3638\ttravel         \t\t-5.9641\theard          \n",
      "\t-6.3570\thigh           \t\t-5.9693\tteam           \n",
      "\t-6.3492\tluck           \t\t-5.9755\tclose          \n",
      "\t-6.3342\twont           \t\t-5.9831\tteacher        \n",
      "\t-6.3312\ttook           \t\t-5.9845\tbit            \n",
      "\t-6.3241\tstop           \t\t-5.9862\tfan            \n",
      "\t-6.3229\thot            \t\t-5.9923\tfriday         \n",
      "\t-6.3226\tcuddle         \t\t-5.9951\twatching       \n",
      "\t-6.3179\tchange         \t\t-5.9956\tcheck          \n",
      "\t-6.3137\tthinking       \t\t-5.9972\tmom            \n",
      "\t-6.3120\tjealous        \t\t-6.0005\thelp           \n",
      "\t-6.3039\tsuck           \t\t-6.0020\teye            \n",
      "\t-6.3025\tworking        \t\t-6.0034\tcongrats       \n",
      "\t-6.3011\tahh            \t\t-6.0129\tsorry          \n",
      "\t-6.3002\tsoo            \t\t-6.0138\thell           \n",
      "\t-6.2970\tsummer         \t\t-6.0168\thahah          \n",
      "\t-6.2966\tbuy            \t\t-6.0200\task            \n",
      "\t-6.2958\tdude           \t\t-6.0201\tyouu           \n",
      "\t-6.2952\tphoto          \t\t-6.0212\tfavorite       \n",
      "\t-6.2942\twow            \t\t-6.0298\tpic            \n",
      "\t-6.2935\tcalled         \t\t-6.0321\tcut            \n",
      "\t-6.2929\tjoke           \t\t-6.0329\tjoin           \n",
      "\t-6.2860\tsister         \t\t-6.0332\thate           \n",
      "\t-6.2834\tmeet           \t\t-6.0391\thello          \n",
      "\t-6.2805\tshower         \t\t-6.0427\tplaying        \n",
      "\t-6.2703\tmatch          \t\t-6.0526\tturn           \n",
      "\t-6.2662\tbitch          \t\t-6.0526\twan            \n",
      "\t-6.2639\tcool           \t\t-6.0540\tbig            \n",
      "\t-6.2521\tbeat           \t\t-6.0566\thahaha         \n",
      "\t-6.2488\tawesome        \t\t-6.0608\tready          \n",
      "\t-6.2471\tbeautiful      \t\t-6.0719\tomg            \n",
      "\t-6.2447\twin            \t\t-6.0726\tthats          \n",
      "\t-6.2437\tboyfriend      \t\t-6.0735\tyay            \n",
      "\t-6.2414\tpls            \t\t-6.0742\tplay           \n",
      "\t-6.2379\tweek           \t\t-6.0746\tworry          \n",
      "\t-6.2367\tdream          \t\t-6.0798\tsound          \n",
      "\t-6.2358\tdinner         \t\t-6.0945\tfollower       \n",
      "\t-6.2327\tcoming         \t\t-6.0979\tuse            \n",
      "\t-6.2327\tlool           \t\t-6.1118\tmiss           \n",
      "\t-6.2277\tjustin         \t\t-6.1125\tfine           \n",
      "\t-6.2162\tword           \t\t-6.1246\tmovie          \n",
      "\t-6.2126\tdoe            \t\t-6.1324\tguess          \n",
      "\t-6.2100\tlearn          \t\t-6.1377\tleft           \n",
      "\t-6.2092\tfucking        \t\t-6.1417\tface           \n",
      "\t-6.2082\tcar            \t\t-6.1459\texcited        \n",
      "\t-6.2081\tread           \t\t-6.1475\tstarted        \n",
      "\t-6.2048\twoke           \t\t-6.1547\tvideo          \n",
      "\t-6.2041\theart          \t\t-6.1597\tlate           \n",
      "\t-6.2012\tshopping       \t\t-6.1670\tman            \n",
      "\t-6.1995\tmaking         \t\t-6.1670\tpretty         \n",
      "\t-6.1993\tsmh            \t\t-6.1712\tboo            \n",
      "\t-6.1861\tworld          \t\t-6.1734\thard           \n",
      "\t-6.1775\tbelieve        \t\t-6.1775\tbelieve        \n",
      "\t-6.1734\thard           \t\t-6.1861\tworld          \n",
      "\t-6.1712\tboo            \t\t-6.1993\tsmh            \n",
      "\t-6.1670\tpretty         \t\t-6.1995\tmaking         \n",
      "\t-6.1670\tman            \t\t-6.2012\tshopping       \n",
      "\t-6.1597\tlate           \t\t-6.2041\theart          \n",
      "\t-6.1547\tvideo          \t\t-6.2048\twoke           \n",
      "\t-6.1475\tstarted        \t\t-6.2081\tread           \n",
      "\t-6.1459\texcited        \t\t-6.2082\tcar            \n",
      "\t-6.1417\tface           \t\t-6.2092\tfucking        \n",
      "\t-6.1377\tleft           \t\t-6.2100\tlearn          \n",
      "\t-6.1324\tguess          \t\t-6.2126\tdoe            \n",
      "\t-6.1246\tmovie          \t\t-6.2162\tword           \n",
      "\t-6.1125\tfine           \t\t-6.2277\tjustin         \n",
      "\t-6.1118\tmiss           \t\t-6.2327\tlool           \n",
      "\t-6.0979\tuse            \t\t-6.2327\tcoming         \n",
      "\t-6.0945\tfollower       \t\t-6.2358\tdinner         \n",
      "\t-6.0798\tsound          \t\t-6.2367\tdream          \n",
      "\t-6.0746\tworry          \t\t-6.2379\tweek           \n",
      "\t-6.0742\tplay           \t\t-6.2414\tpls            \n",
      "\t-6.0735\tyay            \t\t-6.2437\tboyfriend      \n",
      "\t-6.0726\tthats          \t\t-6.2447\twin            \n",
      "\t-6.0719\tomg            \t\t-6.2471\tbeautiful      \n",
      "\t-6.0608\tready          \t\t-6.2488\tawesome        \n",
      "\t-6.0566\thahaha         \t\t-6.2521\tbeat           \n",
      "\t-6.0540\tbig            \t\t-6.2639\tcool           \n",
      "\t-6.0526\twan            \t\t-6.2662\tbitch          \n",
      "\t-6.0526\tturn           \t\t-6.2703\tmatch          \n",
      "\t-6.0427\tplaying        \t\t-6.2805\tshower         \n",
      "\t-6.0391\thello          \t\t-6.2834\tmeet           \n",
      "\t-6.0332\thate           \t\t-6.2860\tsister         \n",
      "\t-6.0329\tjoin           \t\t-6.2929\tjoke           \n",
      "\t-6.0321\tcut            \t\t-6.2935\tcalled         \n",
      "\t-6.0298\tpic            \t\t-6.2942\twow            \n",
      "\t-6.0212\tfavorite       \t\t-6.2952\tphoto          \n",
      "\t-6.0201\tyouu           \t\t-6.2958\tdude           \n",
      "\t-6.0200\task            \t\t-6.2966\tbuy            \n",
      "\t-6.0168\thahah          \t\t-6.2970\tsummer         \n",
      "\t-6.0138\thell           \t\t-6.3002\tsoo            \n",
      "\t-6.0129\tsorry          \t\t-6.3011\tahh            \n",
      "\t-6.0034\tcongrats       \t\t-6.3025\tworking        \n",
      "\t-6.0020\teye            \t\t-6.3039\tsuck           \n",
      "\t-6.0005\thelp           \t\t-6.3120\tjealous        \n",
      "\t-5.9972\tmom            \t\t-6.3137\tthinking       \n",
      "\t-5.9956\tcheck          \t\t-6.3179\tchange         \n",
      "\t-5.9951\twatching       \t\t-6.3226\tcuddle         \n",
      "\t-5.9923\tfriday         \t\t-6.3229\thot            \n",
      "\t-5.9862\tfan            \t\t-6.3241\tstop           \n",
      "\t-5.9845\tbit            \t\t-6.3312\ttook           \n",
      "\t-5.9831\tteacher        \t\t-6.3342\twont           \n",
      "\t-5.9755\tclose          \t\t-6.3492\tluck           \n",
      "\t-5.9693\tteam           \t\t-6.3570\thigh           \n",
      "\t-5.9641\theard          \t\t-6.3638\ttravel         \n",
      "\t-5.9580\tboy            \t\t-6.3674\thalf           \n",
      "\t-5.9539\tbrother        \t\t-6.3680\tamerican       \n",
      "\t-5.9481\tima            \t\t-6.3691\tharry          \n",
      "\t-5.9464\tdate           \t\t-6.3758\tprom           \n",
      "\t-5.9450\tdoin           \t\t-6.3812\teat            \n",
      "\t-5.9406\tbring          \t\t-6.3903\ttold           \n",
      "\t-5.9383\tphone          \t\t-6.4002\tonline         \n",
      "\t-5.9304\tsaid           \t\t-6.4015\tdick           \n",
      "\t-5.9272\tproud          \t\t-6.4049\tsaying         \n",
      "\t-5.9259\thead           \t\t-6.4094\tespecially     \n",
      "\t-5.9244\tlaugh          \t\t-6.4133\tcrazy          \n",
      "\t-5.9240\tdirection      \t\t-6.4143\tsmall          \n",
      "\t-5.9128\tschool         \t\t-6.4170\tohh            \n",
      "\t-5.9109\ttrue           \t\t-6.4206\tblue           \n",
      "\t-5.9051\tlater          \t\t-6.4261\tfood           \n",
      "\t-5.8793\tglad           \t\t-6.4299\twrong          \n",
      "\t-5.8783\tforever        \t\t-6.4329\tbreak          \n",
      "\t-5.8766\tbest           \t\t-6.4401\tbad            \n",
      "\t-5.8748\till            \t\t-6.4407\teating         \n",
      "\t-5.8743\tlady           \t\t-6.4529\taha            \n",
      "\t-5.8712\twork           \t\t-6.4698\tfacebook       \n",
      "\t-5.8662\tlet            \t\t-6.4712\tticket         \n",
      "\t-5.8616\taww            \t\t-6.4918\tfeeling        \n",
      "\t-5.8589\tsweet          \t\t-6.4919\tsingle         \n",
      "\t-5.8547\tsend           \t\t-6.4921\tbox            \n",
      "\t-5.8540\treason         \t\t-6.4953\tgold           \n",
      "\t-5.8529\tkiss           \t\t-6.4961\treview         \n",
      "\t-5.8492\tseriously      \t\t-6.5056\twhite          \n",
      "\t-5.8488\tfeel           \t\t-6.5127\ttrack          \n",
      "\t-5.8484\thair           \t\t-6.5177\tused           \n",
      "\t-5.8472\twatch          \t\t-6.5183\tanymore        \n",
      "\t-5.8379\tearly          \t\t-6.5384\twear           \n",
      "\t-5.8326\tlmao           \t\t-6.5400\tspecial        \n",
      "\t-5.8275\tthought        \t\t-6.5432\tdog            \n",
      "\t-5.8252\tstay           \t\t-6.5452\tdidnt          \n",
      "\t-5.8167\tlooking        \t\t-6.5531\tnotice         \n",
      "\t-5.8127\tweekend        \t\t-6.5574\tfall           \n",
      "\t-5.8120\told            \t\t-6.5681\treply          \n",
      "\t-5.8025\tdont           \t\t-6.5849\tlil            \n",
      "\t-5.7968\tbed            \t\t-6.5908\tleaving        \n",
      "\t-5.7957\tbaby           \t\t-6.5987\tcover          \n",
      "\t-5.7888\tfun            \t\t-6.6116\ttired          \n",
      "\t-5.7864\twish           \t\t-6.6137\tlost           \n",
      "\t-5.7817\tfriend         \t\t-6.6141\tsaw            \n",
      "\t-5.7801\tcute           \t\t-6.6468\thappened       \n",
      "\t-5.7683\thour           \t\t-6.6575\tlight          \n",
      "\t-5.7671\tpicture        \t\t-6.6595\tstar           \n",
      "\t-5.7614\ttalking        \t\t-6.6695\tred            \n",
      "\t-5.7538\tremember       \t\t-6.6875\tsaturday       \n",
      "\t-5.7500\ttrying         \t\t-6.6960\tline           \n",
      "\t-5.7254\tshit           \t\t-6.6992\tseen           \n",
      "\t-5.7249\tcause          \t\t-6.7056\tmissing        \n",
      "\t-5.7177\tgame           \t\t-6.7062\tanswer         \n",
      "\t-5.7173\ttext           \t\t-6.7065\tstand          \n",
      "\t-5.7120\ttry            \t\t-6.7073\twanted         \n",
      "\t-5.7059\thehe           \t\t-6.7173\tnoo            \n",
      "\t-5.6956\tmean           \t\t-6.7185\tdad            \n",
      "\t-5.6914\tlittle         \t\t-6.7193\tcare           \n",
      "\t-5.6872\tactually       \t\t-6.7275\tbook           \n",
      "\t-5.6859\ttomorrow       \t\t-6.7482\twoman          \n",
      "\t-5.6846\tfree           \t\t-6.7515\tshare          \n",
      "\t-5.6804\tclass          \t\t-6.7769\tshort          \n",
      "\t-5.6793\tamazing        \t\t-6.7883\tperson         \n",
      "\t-5.6687\treal           \t\t-6.7932\tgreen          \n",
      "\t-5.6288\ttell           \t\t-6.7970\tstudy          \n",
      "\t-5.6082\tthing          \t\t-6.8026\tcold           \n",
      "\t-5.5718\tnice           \t\t-6.8222\tsomebody       \n",
      "\t-5.5636\tokay           \t\t-6.8430\tmissed         \n",
      "\t-5.5617\ttonight        \t\t-6.8538\tseries         \n",
      "\t-5.5600\tlive           \t\t-6.8715\twood           \n",
      "\t-5.5537\tgon            \t\t-6.8958\tset            \n",
      "\t-5.5502\ttho            \t\t-6.8966\tend            \n",
      "\t-5.5459\tgod            \t\t-6.8985\tblack          \n",
      "\t-5.5362\tlot            \t\t-6.9194\tfast           \n",
      "\t-5.5294\tstart          \t\t-6.9210\tstory          \n",
      "\t-5.5176\tyear           \t\t-6.9219\tjob            \n",
      "\t-5.5154\tfollowing      \t\t-6.9251\tsick           \n",
      "\t-5.5104\tsmile          \t\t-6.9256\tcase           \n",
      "\t-5.5030\tlong           \t\t-6.9299\tmum            \n",
      "\t-5.5007\tsoon           \t\t-6.9510\tpower          \n",
      "\t-5.5006\tmaybe          \t\t-6.9529\tenglish        \n",
      "\t-5.4910\tmind           \t\t-6.9587\tmoney          \n",
      "\t-5.4901\tway            \t\t-6.9675\taway           \n",
      "\t-5.4844\tha             \t\t-6.9730\tbusy           \n",
      "\t-5.4815\tsure           \t\t-6.9740\tplayer         \n",
      "\t-5.4630\tpeople         \t\t-6.9965\tawake          \n",
      "\t-5.4069\tmorning        \t\t-7.0029\tholiday        \n",
      "\t-5.4055\tlife           \t\t-7.0038\tpaper          \n",
      "\t-5.3841\tyes            \t\t-7.0106\tpost           \n",
      "\t-5.3802\tguy            \t\t-7.0136\tbarca          \n",
      "\t-5.3797\ttwitter        \t\t-7.0167\tidk            \n",
      "\t-5.3685\tsleep          \t\t-7.0180\thurt           \n",
      "\t-5.3669\tsong           \t\t-7.0191\ttech           \n",
      "\t-5.3601\treally         \t\t-7.0218\tdesign         \n",
      "\t-5.3165\tsay            \t\t-7.0345\tweather        \n",
      "\t-5.3057\tnew            \t\t-7.0401\tago            \n",
      "\t-5.3017\thome           \t\t-7.0555\tcont           \n",
      "\t-5.2997\tgreat          \t\t-7.0646\twent           \n",
      "\t-5.2953\tna             \t\t-7.1054\tfinal          \n",
      "\t-5.2806\tgetting        \t\t-7.1295\tbrown          \n",
      "\t-5.2174\tbetter         \t\t-7.3987\tworst          \n",
      "\t-5.1881\tneed           \t\t-7.3987\twide           \n",
      "\t-5.1802\tbirthday       \t\t-7.3987\ttoy            \n",
      "\t-5.1706\tyeah           \t\t-7.3987\ttest           \n",
      "\t-5.1654\ttweet          \t\t-7.3987\tsilver         \n",
      "\t-5.1577\they            \t\t-7.3987\tseason         \n",
      "\t-5.1452\tthink          \t\t-7.3987\tscience        \n",
      "\t-5.1182\tright          \t\t-7.3987\tsad            \n",
      "\t-5.0932\tlook           \t\t-7.3987\treplacement    \n",
      "\t-5.0873\thope           \t\t-7.3987\tram            \n",
      "\t-5.0752\tcome           \t\t-7.3987\train           \n",
      "\t-5.0583\thappy          \t\t-7.3987\tposter         \n",
      "\t-5.0206\tgoing          \t\t-7.3987\tpaperback      \n",
      "\t-4.9858\ttoday          \t\t-7.3987\tpack           \n",
      "\t-4.9688\twait           \t\t-7.3987\tmemory         \n",
      "\t-4.8864\tnight          \t\t-7.3987\tkit            \n",
      "\t-4.8744\tmake           \t\t-7.3987\tinch           \n",
      "\t-4.8598\tgirl           \t\t-7.3987\thealth         \n",
      "\t-4.7327\twant           \t\t-7.3987\thardcover      \n",
      "\t-4.7247\tthank          \t\t-7.3987\tglass          \n",
      "\t-4.6852\twa             \t\t-7.3987\tframe          \n",
      "\t-4.5869\thaha           \t\t-7.3987\telectronics    \n",
      "\t-4.5181\tgot            \t\t-7.3987\tedition        \n",
      "\t-4.4748\ttime           \t\t-7.3987\tdvd            \n",
      "\t-4.4074\tknow           \t\t-7.3987\tdigital        \n",
      "\t-4.3498\tday            \t\t-7.3987\tdamn           \n",
      "\t-4.3019\tlol            \t\t-7.3987\tcustom         \n",
      "\t-4.2742\tlike           \t\t-7.3987\tcomplete       \n",
      "\t-4.2666\tthanks         \t\t-7.3987\tcollege        \n",
      "\t-4.1766\tfollow         \t\t-7.3987\tcamera         \n",
      "\t-4.1579\tgood           \t\t-7.3987\tbrand          \n",
      "\t-4.0926\tlove           \t\t-7.3987\tbattery        \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(tfidf_vectorizer, nbclf, n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K fold Cross validation & Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(tweets['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score:  0.673367983692\n"
     ]
    }
   ],
   "source": [
    "# need to do a for loop to find best alpha param (when get access to server)\n",
    "naivebayesclf = MultinomialNB()\n",
    "avg_test_accuracy, cv_bayes = cross_validation(naivebayesclf , tweets.shape[0], tfidf_train_vectors, tweets['sentiment'], n_folds=kfold['naive_bayes'])\n",
    "print('avg score: ',avg_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests (Model Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg score:  0.651044957284\n"
     ]
    }
   ],
   "source": [
    "# need to do a for loop to find best parameters (when get access to server)\n",
    "forest_clf = RandomForestClassifier(n_estimators=100,max_depth=100,n_jobs=-1,random_state=4)\n",
    "avg_test_accuracy, cv_forest = cross_validation(forest_clf , tweets.shape[0], tfidf_train_vectors, tweets['sentiment'], n_folds=kfold['random_forest'])\n",
    "print('avg score: ',avg_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(naivebayesclf, 'Learning Curve - Naive Bayes', tfidf_train_vectors, tweets['sentiment'], cv=cv_bayes)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(forest_clf, 'Learning Curve - Random Forest', tfidf_train_vectors, tweets['sentiment'], cv=cv_forest)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actually',\n",
       " 'ago',\n",
       " 'aha',\n",
       " 'ahh',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'answer',\n",
       " 'anymore',\n",
       " 'anyways',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'awake',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'aww',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'bad',\n",
       " 'barca',\n",
       " 'battery',\n",
       " 'beach',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'bed',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'black',\n",
       " 'blue',\n",
       " 'body',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'brother',\n",
       " 'brown',\n",
       " 'btw',\n",
       " 'busy',\n",
       " 'buy',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'car',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cause',\n",
       " 'cell',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'check',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'close',\n",
       " 'cold',\n",
       " 'college',\n",
       " 'color',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'complete',\n",
       " 'congrats',\n",
       " 'cont',\n",
       " 'cool',\n",
       " 'course',\n",
       " 'cover',\n",
       " 'crazy',\n",
       " 'cuddle',\n",
       " 'custom',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'dad',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'date',\n",
       " 'day',\n",
       " 'ddr',\n",
       " 'design',\n",
       " 'dick',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'digital',\n",
       " 'dinner',\n",
       " 'direction',\n",
       " 'doe',\n",
       " 'dog',\n",
       " 'doin',\n",
       " 'dont',\n",
       " 'dream',\n",
       " 'dude',\n",
       " 'dvd',\n",
       " 'early',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'edition',\n",
       " 'electronics',\n",
       " 'end',\n",
       " 'english',\n",
       " 'especially',\n",
       " 'exam',\n",
       " 'excited',\n",
       " 'extra',\n",
       " 'eye',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fall',\n",
       " 'fan',\n",
       " 'fast',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'final',\n",
       " 'fine',\n",
       " 'follow',\n",
       " 'follower',\n",
       " 'following',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'forever',\n",
       " 'forgot',\n",
       " 'forward',\n",
       " 'frame',\n",
       " 'free',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'getting',\n",
       " 'girl',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'god',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'gon',\n",
       " 'good',\n",
       " 'goodnight',\n",
       " 'got',\n",
       " 'great',\n",
       " 'green',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'ha',\n",
       " 'haha',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahah',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'happened',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hardcover',\n",
       " 'harry',\n",
       " 'hate',\n",
       " 'head',\n",
       " 'health',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'hehe',\n",
       " 'hell',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'high',\n",
       " 'hmm',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hopefully',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hurt',\n",
       " 'idk',\n",
       " 'ill',\n",
       " 'ima',\n",
       " 'inch',\n",
       " 'jealous',\n",
       " 'job',\n",
       " 'join',\n",
       " 'joke',\n",
       " 'justin',\n",
       " 'kiss',\n",
       " 'kit',\n",
       " 'know',\n",
       " 'lady',\n",
       " 'late',\n",
       " 'later',\n",
       " 'laugh',\n",
       " 'learn',\n",
       " 'leaving',\n",
       " 'left',\n",
       " 'let',\n",
       " 'liam',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'lil',\n",
       " 'line',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lmao',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'lool',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'luck',\n",
       " 'lucky',\n",
       " 'mah',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'match',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'meet',\n",
       " 'memory',\n",
       " 'mind',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'mom',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'morning',\n",
       " 'movie',\n",
       " 'mum',\n",
       " 'music',\n",
       " 'na',\n",
       " 'need',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'noo',\n",
       " 'notice',\n",
       " 'ohh',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'online',\n",
       " 'oomf',\n",
       " 'ounce',\n",
       " 'pack',\n",
       " 'paper',\n",
       " 'paperback',\n",
       " 'past',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'photo',\n",
       " 'pic',\n",
       " 'picture',\n",
       " 'place',\n",
       " 'play',\n",
       " 'player',\n",
       " 'playing',\n",
       " 'pls',\n",
       " 'post',\n",
       " 'poster',\n",
       " 'power',\n",
       " 'pretty',\n",
       " 'probably',\n",
       " 'prom',\n",
       " 'proud',\n",
       " 'radio',\n",
       " 'rain',\n",
       " 'ram',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'red',\n",
       " 'remember',\n",
       " 'replacement',\n",
       " 'reply',\n",
       " 'rest',\n",
       " 'retweet',\n",
       " 'review',\n",
       " 'right',\n",
       " 'room',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'saturday',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'school',\n",
       " 'science',\n",
       " 'season',\n",
       " 'second',\n",
       " 'seen',\n",
       " 'send',\n",
       " 'series',\n",
       " 'seriously',\n",
       " 'set',\n",
       " 'sex',\n",
       " 'share',\n",
       " 'shit',\n",
       " 'shopping',\n",
       " 'short',\n",
       " 'shower',\n",
       " 'sick',\n",
       " 'silver',\n",
       " 'single',\n",
       " 'sister',\n",
       " 'sleep',\n",
       " 'small',\n",
       " 'smh',\n",
       " 'smile',\n",
       " 'somebody',\n",
       " 'song',\n",
       " 'soo',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'sound',\n",
       " 'special',\n",
       " 'stand',\n",
       " 'star',\n",
       " 'start',\n",
       " 'started',\n",
       " 'starting',\n",
       " 'stay',\n",
       " 'stick',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'study',\n",
       " 'stuff',\n",
       " 'suck',\n",
       " 'summer',\n",
       " 'sure',\n",
       " 'sweet',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'teacher',\n",
       " 'team',\n",
       " 'tech',\n",
       " 'tell',\n",
       " 'test',\n",
       " 'text',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thats',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'tho',\n",
       " 'thought',\n",
       " 'ticket',\n",
       " 'till',\n",
       " 'time',\n",
       " 'tired',\n",
       " 'today',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'town',\n",
       " 'toy',\n",
       " 'track',\n",
       " 'travel',\n",
       " 'tried',\n",
       " 'true',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'tweet',\n",
       " 'twitter',\n",
       " 'usa',\n",
       " 'use',\n",
       " 'used',\n",
       " 'video',\n",
       " 'voice',\n",
       " 'wa',\n",
       " 'wait',\n",
       " 'wan',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'watch',\n",
       " 'watching',\n",
       " 'way',\n",
       " 'wear',\n",
       " 'weather',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'went',\n",
       " 'white',\n",
       " 'wide',\n",
       " 'win',\n",
       " 'wish',\n",
       " 'woke',\n",
       " 'woman',\n",
       " 'wont',\n",
       " 'wood',\n",
       " 'word',\n",
       " 'work',\n",
       " 'working',\n",
       " 'world',\n",
       " 'worry',\n",
       " 'worst',\n",
       " 'wow',\n",
       " 'wrong',\n",
       " 'yay',\n",
       " 'yea',\n",
       " 'yeah',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'youu']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf_vectorizer.vocabulary_\n",
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Settings:\n",
      "\n",
      "furl :\t True\n",
      "fpunctuation :\t True\n",
      "fsmall_words :\t True\n",
      "fdigits :\t True\n",
      "fduplicates :\t True\n",
      "frepeated_chars :\t True\n",
      "save :\t False\n",
      "fuser :\t True\n",
      "fhashtag :\t True\n",
      "-\n",
      "\n",
      "Tweets Preprocessing for the Training set started\n",
      "\n",
      "\n",
      "There is no cached file for preprocessed tweets\n",
      "\n",
      "Repeated characters filtering DONE\n",
      "Punctuation filtering DONE\n",
      "User filtering DONE\n",
      "Url filtering DONE\n",
      "Hashtag filtering DONE\n",
      "Digits DONE\n",
      "Small words filtering DONE\n",
      "\n",
      " Preprocessed tweets did not saved...\n",
      "\n",
      "Tweets Preprocessing have been successfully finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sea doo pro sea scooter sports with the portab...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shucks well work all week now can come cheer y...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cant stay away from bug thats baby</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lol perfectly fine and not contagious anymore ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whenever fall asleep watching the always wake ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0  sea doo pro sea scooter sports with the portab...        NaN\n",
       "1  shucks well work all week now can come cheer y...        NaN\n",
       "2                 cant stay away from bug thats baby        NaN\n",
       "3  lol perfectly fine and not contagious anymore ...        NaN\n",
       "4  whenever fall asleep watching the always wake ...        NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets = preprocessing(test_tweets,train=False, params=preprocessing_params)\n",
    "test_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_clf = MultinomialNB()\n",
    "tfidf_train_vectors = tfidf_vectorizer.fit_transform(tweets['tweet'])\n",
    "test_data = tfidf_vectorizer.transform(test_tweets['tweet'])\n",
    "final_clf.fit(tfidf_train_vectors, tweets['sentiment'])\n",
    "pred = final_clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_csv_submission(pred, DATA_PATH+PRED_SUBMISSION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code & Useful stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "len(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.vocabulary_['follow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem studying: studi\n",
      "Lemmatise studying: studying\n",
      "Lemmatise studying: study\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    " \n",
    "stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()\n",
    " \n",
    "print(\"Stem %s: %s\" % (\"studying\", stemmer.stem(\"studying\")))\n",
    "print(\"Lemmatise %s: %s\" % (\"studying\", lemmatiser.lemmatize(\"studying\")))\n",
    "print(\"Lemmatise %s: %s\" % (\"studying\", lemmatiser.lemmatize(\"studying\", pos=\"v\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
